pip install kaggle
kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri
import zipfile
import os
# Path to the uploaded .zip file
zip_path = "brain-tumor-classification-mri.zip"
# Directory to extract the files
extract_dir = "brain-tumor-classification-mri"# Create the extraction directory if it doesn't exist
if not os.path.exists(extract_dir):
    os.makedirs(extract_dir)

# Extract the .zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print(f"Extracted files to: {extract_dir}")

import os
import cv2
import matplotlib.pyplot as plt

# Path to the dataset
dataset_path = "brain-tumor-classification-mri"  # Relative path to the dataset folder

# List the subfolders (Testing and Training)
subfolders = ["Testing", "Training"]

# List the classes (tumor types)
classes = ["glioma_tumor", "meningioma_tumor", "pituitary_tumor", "no_tumor"]

# Visualize one image from each class
plt.figure(figsize=(10, 10))
for i, class_name in enumerate(classes):
    # Construct the path to the class folder in the Testing subfolder
    class_path = os.path.join(dataset_path, "Testing", class_name)
    
    # Skip hidden folders (e.g., .ipynb_checkpoints)
    if not os.path.isdir(class_path) or class_name.startswith('.'):
        continue
    
    # Get the list of image files in the folder
    image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
    
    # Check if there are any valid image files
    if not image_files:
        print(f"No valid images found in: {class_path}")
        continue
    
    # Get the first image in the folder
    image_name = image_files[0]
    image_path = os.path.join(class_path, image_name)
    
    # Debugging: Print the image path and check if the file exists
    print("Image Path:", image_path)
    if not os.path.exists(image_path):
        print("File does not exist.")
        continue
    
    # Read the image
    image = cv2.imread(image_path)
    if image is None:
        print(f"Failed to read image: {image_path}")
        continue
    
    # Convert to RGB for visualization
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Plot the image
    plt.subplot(2, 2, i + 1)
    plt.imshow(image)
    plt.title(class_name)
    plt.axis("off")
plt.show()
# Save the plot as an image
plt.savefig("brain_tumor_visualization.png")

# Resize Images
import os
import cv2
import numpy as np

# Path to the dataset
dataset_path = "brain-tumor-classification-mri"

# Target image size
target_size = (128, 128)

# Function to resize images
def resize_images(folder_path, target_size):
    resized_images = []
    for image_name in os.listdir(folder_path):
        image_path = os.path.join(folder_path, image_name)
        image = cv2.imread(image_path)
        if image is not None:
            resized_image = cv2.resize(image, target_size)
            resized_images.append(resized_image)
    return resized_images

# Resize images for each class
resized_data = {}
for class_name in ["glioma_tumor", "meningioma_tumor", "pituitary_tumor", "no_tumor"]:
    class_path = os.path.join(dataset_path, "Testing", class_name)
    resized_data[class_name] = resize_images(class_path, target_size)

# Check the shape of resized images
for class_name, images in resized_data.items():
    print(f"{class_name}: {len(images)} images, Shape: {images[0].shape}")

# Normalize Pixel Values
# Normalize pixel values
normalized_data = {}
for class_name, images in resized_data.items():
    normalized_data[class_name] = [image / 255.0 for image in images]

# Check the pixel range
for class_name, images in normalized_data.items():
    print(f"{class_name}: Min={np.min(images[0])}, Max={np.max(images[0])}")

# Split The Data
from sklearn.model_selection import train_test_split

# Combine images and labels
X = []
y = []
for class_name, images in normalized_data.items():
    X.extend(images)
    y.extend([class_name] * len(images))

# Convert to NumPy arrays
X = np.array(X)
y = np.array(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training data: {X_train.shape}, {y_train.shape}")
print(f"Testing data: {X_test.shape}, {y_test.shape}")

# Handling Class Imbalance
# Check class distribution
from collections import Counter

print("Training class distribution:", Counter(y_train))
print("Testing class distribution:", Counter(y_test))

# Save the Preprocessed Data
import pickle

# Save the preprocessed data
with open("preprocessed_data.pkl", "wb") as f:
    pickle.dump((X_train, X_test, y_train, y_test), f)

print("Preprocessed data saved to preprocessed_data.pkl")

# AI Model Development
from sklearn.preprocessing import LabelEncoder

# Encode labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Check the encoded labels
print("Encoded Training Labels:", y_train_encoded)
print("Encoded Testing Labels:", y_test_encoded)







