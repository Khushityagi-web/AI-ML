pip install kaggle
kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri
import zipfile
import os
# Path to the uploaded .zip file
zip_path = "brain-tumor-classification-mri.zip"
# Directory to extract the files
extract_dir = "brain-tumor-classification-mri"# Create the extraction directory if it doesn't exist
if not os.path.exists(extract_dir):
    os.makedirs(extract_dir)

# Extract the .zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print(f"Extracted files to: {extract_dir}")

import os
import cv2
import matplotlib.pyplot as plt

# Path to the dataset
dataset_path = "brain-tumor-classification-mri"  # Relative path to the dataset folder

# List the subfolders (Testing and Training)
subfolders = ["Testing", "Training"]

# List the classes (tumor types)
classes = ["glioma_tumor", "meningioma_tumor", "pituitary_tumor", "no_tumor"]

# Visualize one image from each class
plt.figure(figsize=(10, 10))
for i, class_name in enumerate(classes):
    # Construct the path to the class folder in the Testing subfolder
    class_path = os.path.join(dataset_path, "Testing", class_name)
    
    # Skip hidden folders (e.g., .ipynb_checkpoints)
    if not os.path.isdir(class_path) or class_name.startswith('.'):
        continue
    
    # Get the list of image files in the folder
    image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
    
    # Check if there are any valid image files
    if not image_files:
        print(f"No valid images found in: {class_path}")
        continue
    
    # Get the first image in the folder
    image_name = image_files[0]
    image_path = os.path.join(class_path, image_name)
    
    # Debugging: Print the image path and check if the file exists
    print("Image Path:", image_path)
    if not os.path.exists(image_path):
        print("File does not exist.")
        continue
    
    # Read the image
    image = cv2.imread(image_path)
    if image is None:
        print(f"Failed to read image: {image_path}")
        continue
    
    # Convert to RGB for visualization
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Plot the image
    plt.subplot(2, 2, i + 1)
    plt.imshow(image)
    plt.title(class_name)
    plt.axis("off")
plt.show()
# Save the plot as an image
plt.savefig("brain_tumor_visualization.png")

# Resize Images
import os
import cv2
import numpy as np

# Path to the dataset
dataset_path = "brain-tumor-classification-mri"

# Target image size
target_size = (128, 128)

# Function to resize images
def resize_images(folder_path, target_size):
    resized_images = []
    for image_name in os.listdir(folder_path):
        image_path = os.path.join(folder_path, image_name)
        image = cv2.imread(image_path)
        if image is not None:
            resized_image = cv2.resize(image, target_size)
            resized_images.append(resized_image)
    return resized_images

# Resize images for each class
resized_data = {}
for class_name in ["glioma_tumor", "meningioma_tumor", "pituitary_tumor", "no_tumor"]:
    class_path = os.path.join(dataset_path, "Testing", class_name)
    resized_data[class_name] = resize_images(class_path, target_size)

# Check the shape of resized images
for class_name, images in resized_data.items():
    print(f"{class_name}: {len(images)} images, Shape: {images[0].shape}")

# Normalize Pixel Values
# Normalize pixel values
normalized_data = {}
for class_name, images in resized_data.items():
    normalized_data[class_name] = [image / 255.0 for image in images]

# Check the pixel range
for class_name, images in normalized_data.items():
    print(f"{class_name}: Min={np.min(images[0])}, Max={np.max(images[0])}")

# Split The Data
from sklearn.model_selection import train_test_split

# Combine images and labels
X = []
y = []
for class_name, images in normalized_data.items():
    X.extend(images)
    y.extend([class_name] * len(images))

# Convert to NumPy arrays
X = np.array(X)
y = np.array(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training data: {X_train.shape}, {y_train.shape}")
print(f"Testing data: {X_test.shape}, {y_test.shape}")

# Handling Class Imbalance
# Check class distribution
from collections import Counter

print("Training class distribution:", Counter(y_train))
print("Testing class distribution:", Counter(y_test))

# Save the Preprocessed Data
import pickle

# Save the preprocessed data
with open("preprocessed_data.pkl", "wb") as f:
    pickle.dump((X_train, X_test, y_train, y_test), f)

print("Preprocessed data saved to preprocessed_data.pkl")

# AI Model Development
from sklearn.preprocessing import LabelEncoder

# Encode labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Check the encoded labels
print("Encoded Training Labels:", y_train_encoded)
print("Encoded Testing Labels:", y_test_encoded)

import tensorflow as tf
from tensorflow.keras import layers, models

# Define the CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(4, activation='softmax')  # 4 classes
])

# Display the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
# Train the model
history = model.fit(X_train, y_train_encoded, epochs=10, validation_split=0.2)
# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")
# Save the model
model.save("brain_tumor_cnn_model.h5")
print("Model saved as brain_tumor_cnn_model.h5")
from tensorflow.keras import layers, models

# Define the CNN model with dropout
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),  # Add dropout
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),  # Add dropout
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),  # Add dropout
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),  # Add dropout
    layers.Dense(4, activation='softmax')  # 4 classes
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

print("CNN model with dropout built and compiled.")
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Fit the data generator to the training data
datagen.fit(X_train)
# Train the model with data augmentation
history = model.fit(datagen.flow(X_train, y_train_encoded, batch_size=32),
                    epochs=20,  # Increase epochs
                    validation_data=(X_test, y_test_encoded))

print("Model training with dropout and data augmentation completed.")
# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")
# Save the model
model.save("brain_tumor_cnn_improved_model.h5")
print("Improved model saved as brain_tumor_cnn_improved_model.h5")









